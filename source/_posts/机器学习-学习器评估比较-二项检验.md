---
title: 机器学习-学习器评估比较-二项检验
abbrlink: d566d08d
date: 2025-12-19 10:35:52
tags:
- 二项检验
categories:
- - 机器学习
top: 1005
mathjax: true
description: 无
---
统计假设检验可以用来对学习器的性能进行比较。基于假设检验结果可以推断出，若在测试集上观察到学习器A的效果比B号，  
那么A的泛化性能是否在统计意义上优于B，以及这个结论的把握有多大。  
假设检验中的“假设”是对泛化错误率分布的某种判断或者猜想，例如$\epsilon==epsilon_0$。  
在现实任务中我们不知道学习器的泛化错误率，只能获知其测试错误率$\hat{\epsilon}$。泛化错误率与测试错误率并不一定相同，  
但从感觉上来说，两者相近的概率较大，相差很远的概率很小。因此可以根据测试错误率推出泛化错误率的分布。
泛化错误率为学习器在一个样本上错误的概率$\epsilon$；测试错误率则是对于某个学习器决策错误的样本与样本的总数比值。  
及对于$m$个测试样本中恰好有$\hat{\epsilon} \times  m$等于测试错误的数量。假定测试样本是从总体样本中独立采样得来的，  
那么泛化错误率为$\epsilon$的学习器讲$m'$个岩本误分类，其余样本全部正确分类的概率是$\epsilon^{m}(1-\epsilon)^{(m-m')}$  
由此可估算出其恰好将$\hat{\epsilon}\times m$个样本错误分类的概率为
$$
P(\hat{\epsilon};\epsilon)=\binom{m}{\hat{\epsilon }\times m} \epsilon^{\epsilon \times m}(1-\epsilon)^{(m-\hat{\epsilon} \times m)}
$$
当测试错误率一定的时候这是一个关于$\epsilon$的一元函数，若要使$P(\hat{\epsilon};\epsilon)$即在泛化错误率为$\epsilon$的情况下测试错误率为$\hat{\epsilon}$的概率最大  
对$\epsilon$偏导，当偏导数为0的时候取局部的极值
令$k=\hat{\epsilon}\times m$有
$$
\begin{align}
\frac{\partial P(\hat{\epsilon};\epsilon)}{\partial \epsilon}&=\frac{\partial \binom{m}{k} \epsilon^{k}(1-\epsilon)^{(m-k)}}{\partial \epsilon}\\\\
&= \binom{m}{k} \times \frac{\partial \epsilon^{k}(1-\epsilon)^{(m-k)}}{\partial \epsilon} \\\\
&= \binom{m}{k} \times k\epsilon^{(k-1)}(1-\epsilon)^{(m-k)}-\epsilon^k(m-k)(1-\epsilon)^{(m-k-1)}\\\\
&= \binom{m}{k} \times (1-\epsilon)^{(m-k-1)}(k\epsilon^{(k-1)}(1-\epsilon)-\epsilon^k(m-k))\\\\
&= \binom{m}{k} \times (1-\epsilon)^{(m-k-1)}(k\epsilon^{(k-1)}-k\epsilon^{k}-\epsilon^k(m-k))\\\\
&= \binom{m}{k} \times (1-\epsilon)^{(m-k-1)}(k\epsilon^{(k-1)}-m\epsilon^k)\\\\
&= \binom{m}{k} \times (1-\epsilon)^{(m-k-1)}\epsilon^{(k-1)}(k-m\epsilon)\\\\
&= \binom{m}{\hat{\epsilon}\times m} \times (1-\epsilon)^{(m-\hat{\epsilon}\times m-1)}\epsilon^{(\hat{\epsilon}\times m-1)}(\hat{\epsilon}\times m-m\epsilon)\\\\
&= \binom{m}{\hat{\epsilon}\times m} \times (1-\epsilon)^{(m-\hat{\epsilon}\times m-1)}\epsilon^{(\hat{\epsilon}\times m-1)}m(\hat{\epsilon}-\epsilon) \tag{1}
\end{align}
$$
